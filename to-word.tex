\documentclass[12pt,letterpaper]{article}

% enable text super- and sub- scripts
\usepackage{xltxtra}
\usepackage{caption}
% let us typeset things inside the captions
\captionsetup{justification=justified}

\usepackage{graphicx}
% used for pmatrix
\usepackage{amsmath}
\usepackage{array}

\usepackage[sc,osf]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{inconsolata}

% use fancy syntax highlighting provided by an interface to pygments
\usepackage{minted}

%\usepackage[margin=.75in,nohead,nofoot]{geometry}⋅
\usepackage[nohead]{geometry}
\usepackage{hyperref}
\usepackage[authoryear,round]{natbib}

% named colors, package already included with minted
\definecolor{DBlue}{rgb}{0.19,0.32,0.50}
\definecolor{DRed}{rgb}{0.7,0.22,0.21}
\definecolor{DGreen}{rgb}{0.15,0.41,0.15}
\definecolor{LGreen}{rgb}{0.01,0.62,0}

\newcommand{\R}{\textsf{R}}
\newcommand{\Rcmd}[1]{\texttt{#1}}

%\setlength{\parskip}{0.05in}
\linespread{1.2}

\geometry{
  body={6.5in, 8.75in},
  left=1.0in,
  top=1.0in,
  right=1.0in,
  bottom=1.0in
}

\hypersetup{
  colorlinks = true,
  urlcolor = black,
  citecolor = blue
}

\renewcommand{\theFancyVerbLine}{\sffamily\textcolor[rgb]{0.5,0.5,0.5}{\scriptsize\arabic{FancyVerbLine}}}

% fancy matrix environment which allows vertical bars
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\begin{document}
\title{\Huge{Assessing ship movements using volunteered geographic information}}
\author{Shaun Walbridge}
\maketitle{}

\section{Introduction}

\subsection{Shipping, who cares?}
% XXX REWRITE THIS FIRST PART: NEEDS A PUNCH TO LET PEOPLE KNOW WHY THIS MATTERS.

Shipping, the global transportation of people and goods, provides a useful window into critical issues for geographic information science (GIScience), and its understanding has implications for a variety of applied fields including marine conservation, marine spatial planning, transportation geography, and navigation.  This work examines a synthesis of available shipping data.

GIScience seeks to formalize our understanding of geographic information, and shipping can provide insight into areas of the GIScience agenda. Ship observations are contributed by vessels that submit data on both a voluntarily and mandated basis \citep{VOSClim,Tetreault2002}, affording an opportunity to advance our use of geographic quality checking methods \citep{goodchildli2012} against this volunteered geographic information (VGI) \citep{goodchild2007citizens}. And while individual observations have a simple representation (a location, time, and attributes), effective use requires multiple representations \citep{Goodchild1992} and the spatio-temporal modeling techniques of time geography \citep{miller2008field}.

Shipping places a growing demand on the ocean, transporting \$1.8 trillion dollars of goods annually, %XXX need reference! 
and providing a \$300 billion dollar maritime industry, representing one of the largest economic users of the ocean. This activity impacts both human health and the environment, such as the \$3 billion Exxon-Valdez spill\footnote{The \$5 billion liability for the spill was so great that a now infamous financial instrument was manufactured to absorb it: the credit default swap.}, but largely the effects of shipping remain out of sight. Documented effects include greenhouse gasses, accounting for five percent of total man-made emissions, and causing 60,000 premature deaths per year \citep{Corbett2007}. Ecologically, vessels cause ship strikes which can impair whale populations \citep{Fujiwara2001}, % XXX better refs? 
 transport invasive species, leading to widespread economic and biological losses, cause groundings with a host of direct effects like oil spills and habitat destruction, and produce noise pollution, leading to mortality events. Other ecological and human impacts are likely to exist, but remain unidentified, as shipping continues to be poorly understood~\citep{Davenport2006}. As we try to understand the health of the ocean \citep{Halpern2012}, we need detailed data which poses an acute challenge to ocean scientists~\citep{Wright1997}. This data is necessary to inform decision-making, such as marine spatial planning, but also is important to minimizing the regulatory burden on the shipping industry: by managing shipping as a complex system, efficiency can be tied to improved environmental conditions.

%   + invasive species via ballast water 
%   + ship strikes
%   + noise pollution
%   + groundings (direct effects like oil spills, grey water, chemical spills, smashing coral)
%    * acute damage
%    * chronic damage
%   + certain to be many other ecological and human impacts -- just a poorly understood use of the ocean.

% XXX what are the economic uses mentioned in the OHI paper? put this in context.
Another major, direct economic user of the ocean is fishing, where our understanding has been advanced by intensive investments to study its effects. % XXX citation for this? its clear from spending, but quantify it.
Many fisheries are now managed systems~\citep{worm2009rebuilding}, in part due to frequent \textit{tragedy of the commons} events, leading to the collapse of unmanaged fish stocks~\citep{costello2012status}. % clearly disagreement in the Worm / Jackson / Halpern vs. Hilborn camps, use their joint papers as an end-run around this.
This same management is noticeably absent in the shipping industry.

  Shipping is regulated by the International Maritime Organization (IMO), a branch of the United Nations which enforces rules and standards on the shipping industry. However, the transnational nature of the industry has led to low policy enforcement. As is common in consensus-based international bodies~\citep{cogan2009representation}, the IMO is slow to respond to problems of the day. 
  % XXX have to cite both of these statements if this is gonna stick. INSTEAD: say that they are a CONSENSUS based organization which requires ratification of many international bodies, by its nature a time consuming process. 
  For example, while acknowledging that 20\% reductions in greenhouse gasses can be accomplished in this decade, without additional costs to operators\citep{imo2009}, it hasn't implemented new rules on such gasses.  In light of the weak regulatory environment, alternatives, such as tying ship insurance rates to specific areas of the ocean, may be preferable.
 % an example article on IMO problems: http://articles.cnn.com/2012-07-04/world/world_europe_costa-concordia_1_concordia-disaster-cruise-industry-cruise-ship-disaster/3?_s=PM:EUROPE
 % http://ban.org/ban_news/2006/060316_imo_treaty.html
 % http://www.sourcewatch.org/index.php?title=International_Maritime_Organization#Criticisms_of_the_IMO

%   + other parts of the ocean environment coming into regulation, particularly fishing
%   + Regulation of shipping rudimentary
%    * wild west in terms of control; do regulate emissions in specific places but international agreements minimal (what's IMO got on the table)
%    * part of the problem is that shipping is extremely international, more so than fishing
%    * primary regulation is at ports, otherwise just GPS units and a hope that no one crashes

% FUNDAMENTALLY, doing synthesis on the shipping, with a set of simple rules to validate observations.

\subsection{Transportation networks}

Transportation networks with geographically-fixed edges and nodes, such as road and rail, form the basis of transportation geography \citep{Rodrigue2009}. Unlike these networks, shipping exists in between the extremes of a fixed network % XXX DEFINE, Newman 2010?
 and two dimensional brownian bridges, % XXX DEFINE
  as vessels must transport both goods and passengers to specific locations (primarily ports) but are free in choosing movement between destinations, except in near shore areas regulated by shipping lanes. Air transportation shares network similarities, but strong regulation has led to predetermined flight paths, with deviations generally limited to emergencies or extreme weather. % XXX need a ref here. how does the FAA and the relevant international body regulate movement?

Because of inherent risks in air transportation, detailed, well-vetted information on flight paths is provided by government agencies \citep{guimera2005worldwide}, simplifying modeling. Ship movements have no equivalent top-down data collection effort, and while organizations such as the US Coast Guard have made efforts, the system remains rudimentary. Most information is provided via private contracts, through organisations such as Lloyd's of London, who have been recording information on shipping since 1774 \citep{Lloyd'sRegister-FairplayLtd.2010}. As a result, limited public data is available on the shipping trade, despite being identified by the FGDC~\citep{FGDC} as a key transportation component to the national spatial data infrastructure \citep{CurrierInPress}.

% XXX where are you going with this?
Transportation networks play an important economic role \citep{canning1993effects}. Because of the major economic role, information on shipping is valuable, leading to a cottage industry of information sales and limiting its public availability. Here, we look at using geographically-volunteered information to infer the movement patterns which in part define the shipping network.

% XXX XXX XXX
% EXPAND THIS SECTION TO COMPARE BETWEEN NETWORK TYPES
% TALK ABOUT OTHER MODES OF TRANSPORTATION; [this gives you a way to tame it, its reasonable to assume that it'll map to one of these models]

%   + there are other transportation networks -- road, rail -- that are better understood
%   + a comparison with airlines - both cases, captains have choice of route (follow desire lines) but that is very regulated and lots of data exists
%   + we don't have data in part because this kind of thing was traditionally collected by governments, but they lack the capacity and will to do so now
%   + we also don't have data partially because it is very valuable, and those who have any data (Lloyds) want lots of money for it -- part of the reason there's so little research
%   + Also shipping is generally ignored; FGDC linkage:

% In 1996 the International Steering Committee of Global Map (ISCGM) was established and in 1998 the national mapping agencies of all countries of the world were formally invited to participate in the effort The ISCGM adopted the specifications for Version 1.0 later that year, and by 2000 this version had been completed and was released. The product included eight data layers: vegetation, land cover, land use, elevation, drainage, population centers, boundaries, and transportation.
% -- \cite{CurrierInPress}

% In the United States, the Federal Geographic Data Committee (FGDC) guides the development, use, sharing, and dissemination of geographic data (http://www.fgdc.gov/). This committee has identified seven core themes of critical importance to the nation’s spatial data infrastructure: the cadaster, digital orthoimagery, elevation, geodetic control, governmental unit boundaries, hydrographic features, and transportation networks (FGDC, 2008). In published standards each theme is formalized in a data dictionary, which defines the structural and content requirements that a dataset must satisfy. The standards additionally specify a “minimal level of data content that data producers, consumers and vendors shall use for the description and interchange of those data” (FGDC, 2008:1).
% -- \cite{CurrierInPress}

%From the FGDC docs:
% 1.3.7 Transportation⋅

%Transportation data are used to model the geographic locations, interconnectedness, and characteristics of the transportation system.  The transportation system includes both physical and non-physical components representing all modes of travel that allow the movement of freight and people between locations.  Sub-themes representing the physical components of the transportation infrastructure include airport facilities, waterways, roads, railroads, and transit.  \cite{FGDC}

\subsection{Existing work}

Much research has focused on specific areas within shipping, such as maritime awareness to detect anomalous behavior \citep{Tun2007}, tracking ship-whale interactions \citep{jensen2004large}, or shipping lanes to protect a species \citep{Lagueux2011,Mckenna2012a}.  Few papers, however, tackle shipping as a global phenomena. Two important papers from this limited body of research will now be discussed.

The first work % XXX can I say this really?
to examine the global shipping trade in an ecological context was a synthesis effort to collect information across habitat types and impacts \citep{Halpern2008}. The work evaluates many human uses of the ocean, and gathers together global data to examine the cumulative impact humans have, ranging from changes in sea surface temperature due to radiative forcing, to land-based nutrient runoff. The data used in this analysis to represent shipping, however, has limitations: it ignores vessel classes, % XXX this is the first point at which I mention ship classes, what shipping *IS* should be explained earlier in the document.
 and contains information on only 12\% of the fleet. The ships it does include are a spatially- and statistically-biased sample of the population \citep{Wang2007}. The data is variable between ships, so many areas where there is active use are missing from the model. Finally, the paper does not tackle modeling issues, but instead provides patterns without the context necessary to address deeper questions. % XXX cite the SOM? is that needed?

% - Work on global shipping
%   + Lots of papers that focus on specific parts of the shipping problem - few that take large perspective.
%   + Ben's Science paper
%    * first work that looked at global impact of shipping from ecological context, but wasn't focused on shipping
%    * first work to really look at how humans are affecting marine environment by synthesizing together all available global data
%    * problem with data is that it was based upon unrepresentative ships - missing whole categories of ships; only 12\% of fleet; representation issues (see Corbett \& Wang paper for details)
%    * second problem, uneven spatial distribution - tons of gaps. Data quality highly variable from ship to ship
%     - missing big areas of the ocean that we know lots of ships are using
%    * problem three - doesn't address data models (important for geographers); just says 'ships are here'.

A more recent paper \citep{Kaluza2010} takes a different approach, by focusing on shipping as a network, with an analysis geared toward a network theory audience. Licensing data from Lloyd's of London, % XXX cite?
 the authors aggregate port of call records, which are sequential lists of vessel location. They then extrapolate port to port links into routes, by combining land-based barriers with great circle distance calculations to select the 'path' of a ship between two ports. This novel approach provides a measure of connectivity between port locations, and improves on the gravity model widely used to predict connectivity. % XXX cite
However, this model provides insufficient detail to extract ship movement paths, necessary for resolving many of the conflicts listed above. Instead, we need geographically referenced facts about movement. Additionally, the data used requires expensive licensing, making extending the work financially prohibitive. Despite largely ignoring geography, this paper is currently the best examination of the global shipping trade.

% - Kaluza paper, based on Lloyd's data
%   + written for network theory audience
%   + data is port order for specific ships, which is used to come up with proposed routes of ships based on great circle distances (A to B to C)  
%   + problem - they don't actually know where ships travelled, which means results aren't helpful for problems where ship locations actually matter.
%   + can't share data, it's proprietary
%   + this paper is still the best that looks at shipping at a global level
%   + ignores geography

\subsection{Where this work comes in}

Fusing together data from multiple sources, here I build a dataset useful for interpreting the global shipping trade. While high-resolution (spatially and temporally) volunteered information exists, its use has been limited to regional problems, and existing global work used poor data~\citep{Corbett2007, Halpern2008}. This paper contributes data predominantly within 100km of shores, where most human and biological users of the ocean persist, and building our knowledge of these areas is particularly valuable.

As noted by Goodchild, ``changing technology and economics are moving map production from a system of unified central production to a local patchwork, and the old radial system of dissemination is being replaced with a complex network.''\citep{goodchild1999cartographic} By using quality assurance methods from both computer science and geography, such as record linage and geographic validation, we can filter unreliable inputs. The near future will involve global, real-time, high resolution ship data \citep{JonesGoogle2012,carson2012satellite}, but we continue to need methods which accommodate data curation and integration, and allow us to address specific hypotheses. This is a key appeal of volunteered information: some problems of uncertainty become tractable with sufficient observation volume, as we can evaluate the distribution directly instead of relying on sampling methods.

% XXX XXX this whole last paragraph is sort of bleh, it doesn't really *sell* the work. I'm excited! show it here!

%- building new global datasets of shipping that provide new insights by connecting data together
%- high-res ais data only used for subcontentnal analysis previously - VOSClim used in Halpern 2008, Corbett
%- AIS provides high resolution view at shore, where we tend to care the most
%- combining AIS with VOSClim provides best to date view of how ships travel through ocean
%- use VGI quality approaches to improve data
%- Future will have global AIS coverage \cite{JonesGoogle2012,carson2012satellite}, but still need methods to curate data and integrate our understanding.

\section{\textbf{Methods}}

% how did I solve the problem?

% FUNDAMENTALLY, doing synthesis on the shipping, with a set of simple rules to validate observations.
% shipping as sensor network -- a synthesis.

\subsection{Volunteered vessel information}

%"In short, changing technology and economics are moving map production from a system of unified central production to a local patchwork, and the old radial system of dissemination is being replaced with a complex network."
% -- Goodchild cartography paper, old and captures the change in production that is ongoing.

%\citep{elwood2011researching} includes reference to these same layers, capturing data on 'core' data layers independently. Covers much of what Goodchild has discussed in terms of issues with VGI and its current 'cutting edge'
Historically, ship data was collected both by governments for internal use, and by private corporations with the intent to sell. As elsewhere in the production of geographic facts, a shift is underway which moves the emphasis away from top-down primary data collection, to relying on observations from a multitude of sources \citep{goodchild2007citizens,elwood2011researching}. This new information has the potential to fundamentally change our use of the ocean.

% Using two kinds of volunteered ship data - needs to be handled in special ways:
% describe VOSclim data:
Ship captains have long taken climate observations alongside known locations \citep{brohan2009marine}.  Building on this history, the Voluntary Observing Ship (VOS, \citealp{VOSOverview}) program collected a dataset spanning over 20 years and covering 10\textendash20\% of commercial traffic within each year. Ass the intention was to collect open-ocean climate observations, many of the records lack ship attribute information. % XXX making trajectory reconstruction difficult. 
The data is contained within the greater International Comprehensive Ocean-Atmosphere Data Set (ICOADS, \citealp{woodruff2010icoads}), and though the data is both spatially- and statistically- biased \citep{Wang2007}, it serves as a useful training dataset on ship movements in the open ocean. Here, I use VOS records from 2003--2011, supplemented with opportunistic observations collected by the vessel tracking site SailWX \citep{SAILWX}. On the vessels that do report both attributes and locations, this information is captured at regular intervals, providing difficult to find open ocean observations.
% XXX: what other data does SailWX also include? YOTREPS? what else?

% describe AIS data
The Automatic Identification System (AIS) \citep{no20041028,Tetreault2002} was developed to improve maritime safety and prevent collisions, by providing mariners local situational awareness (Figure \ref{fig:ais-overview}). By locating the ships via global positioning satellite (GPS) fix, and broadcasting the location alongside other attributes (Table \ref{table:ais-broadcast-attributes}) regularly via VHF transceiver, mariners gain real-time local traffic, invaluable in inclement weather or rescue operations \citep{Itu-r2010}.  The International Maritime Organization (IMO) mandates that all ships $\geq\negthickspace 150$ gross tonnage (GT) or ships bearing paid passengers carry AIS units \citep{solas}, which has lead to approximately 200,000 ships being outfitted with AIS equipment, including all licensed tankers, cargo ships and passenger vessels. Because the intent was to improve maritime safety, the system uses well-understood VHF radios, broadcasting to about 40km between ships. Since the system's implementation, land-based users, including ports, maritime professionals and amateurs, have set up VHF antennae, providing low-cost local ship traffic data at a range of up to 100km. Numerous sites now provide real-time feeds, such as MarineTraffic \citep{MarineTraffic} and SailWX, aggregating the records from many land-based antennae (and more recently, satellite feeds) and displaying them over both web maps and via Google Earth. These sites constantly augment their networks by providing in-depth data to those willing to set up AIS receiving stations in geographic areas not yet covered.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=100mm]{images/towers/drawing.pdf}
  \caption{Automated Information System diagram. Ships communicate to one another via VHF broadcast. The same signals can be captured and stored by land- and satellite- based observers.}
  \label{fig:ais-overview}
\end{figure}

\subsection{Data Collection}

For this study, fifteen months of AIS data were collected, from November 2010--December 2011, aggregating records from three major online AIS providers: FleetMon, VesselTracker, and MarineTraffic. All three share Keyhole Markup Language (KML, \citeauthor{KML}) files, intended for Google Earth. Examining data availability (Figure \ref{fig:ais-coverage}) showed these providers had considerably different coverage. At ten minute intervals over the study period, I automated downloading these KML files of real-time ship traffic from each of the providers. I then parsed the files to extract each observation within the dataset, wrote a library to normalize differences between the providers, and inserted the results into a spatial database, (PostGIS, \citeauthor{ramsey2005postgis}), an extension providing support for OGC simple features \citep{OGCSimple} on top of the PostgreSQL \citep{postgresql} object-relational database engine). Over the study period, this provided 2.37 billion observations which all include ship location and time, but frequently include additional attributes (Table \ref{table:ais-broadcast-attributes}).  The VOS/SailWX dataset, consisting of 92.4 million records covering Feburary 1991--September 2011, was provided in a MySQL database dump, which was converted and imported into PostgreSQL. 

Augmenting these ship observations, ancillary data was identified to provide validation against the raw observations, which is described below.

\subsubsection{Vessel attribute data}
Vessel data, tabular lists of ships alongside attributes, was collected from both authoritative and crowd-sourced media (Table \ref{table:ships-data-sources}) from a variety of sources, useful in validating the attributes provided in both VOS and AIS observations. Sources include:
\begin{enumerate}
  \item Within the United States, the Federal Communications Commission (FCC) regulates the airwaves. In order to track and manage radio licenses, the FCC has developed the Consolidated Database System (CDBS), which includes information on all vessels with registered radios within the US. 
  \item The International Telecommunications Union (ITU) created the Maritime mobile Access and Retrieval System (MARS) database to provide the maritime community with the most up-to-date data for registered vessels. Thanks to their role as a regulating body, participant states are required to provide up-to-date information. This database is particularly useful as it includes details not available through other public means, such as the vessel owner, and passenger capacity.
  \item DigitalSeas provided volunteered vessel attribute information, collected primarily through corrected AIS observations, but has since gone off-line.
  \item VesselTracker includes ship tracking, reporting and vessel records, alongside real-time AIS position data. Both their vessel data, and their AIS observations were recorded in this study. The dataset shows particular strength in European waters. Vesseltracker has also developed a ship routing network, but doesn't provide public access to this resource.
\end{enumerate}

\subsubsection{Land-sea mask}
\label{sec:land-sea-mask}
  A high resolution land-sea mask, derived from the Shuttle Radar Topography Mission (SRTM) Water Body Data (SWBD, \citealp{slater2006srtm}), classifies the world into either land or sea at three arcsecond resolution (\textasciitilde{}90m) for much of the world (56$^\circ$ S to 60$^\circ$ N). It was a by-product of the SRTM digital terrain project \citep{rabus2003shuttle}, and has the advantage that the data was collected over a very short period of time, increasing self-consistency.

For the areas beyond that covered by SRTM, the Global Self-consistent, Hierarchical, High-resolution Shoreline Database (GSHHS, \citealp{wessel1996global}) was used, which is an amalgamation of publicly available shoreline data. This data is lower resolution than SWBD, but the vast majority of my observations come from within the SRTM study area. The transition zone between these two layers was manually corrected to make a single, consistent, high-resolution land-sea mask at three arc seconds.

\subsubsection{Other data}
Port databases were collected, containing coordinates and berth details for ports globally. Approximately 5,000 ports were identified from a range of volunteered and authoritative sources.  Approximate information on ship movement patterns was also collected, based on historical charts such as a CIA vessel movement chart from the Cold War~(Figure \ref{fig:cia-shipping-map}). The original ship model produced as part of the previous modeling effort \citep{Halpern2008} was helpful for comparison.

\subsection{Validation}

The raw observations are full of caveats: because of inherent limitations in protocol design, there is no direct way of validating an incoming packet \citep{RaymondInPress}. So, as seen in (Figure \ref{fig:ais-obs-nov-2011}), many locations in the middle of major landmasses have observations, including a particularly thick band centered around the prime meridian. These records are more likely due to corruption of the longitude coordinate than reverence for Greenwich. Alongside transmission errors are operator error: the attributes which are sent alongside the time and position information are input by the mariners, and they may introduce errors in entry, or fail to update the attributes which change over time, such as the destination field. Each observation within this dataset is suspect, and the data should be treated as guilty until proven innocent.

While there are numerous problems with the data, the volume of data, and the compiled ancillary datasets, provide ways to use the data via cross-correlation. This improves accuracy and minimizes the observations required to build a model representation of the data. Two areas relevant to this problem are geographic data mining \citep{miller2009geographic}, and the recent work of \cite{goodchildli2012}. Here, I borrow the framework described in the latter work, and explore three avenues of quality assurance: crowd sourcing, social, and geographic approaches.

% XXX XXX XXX SHOULD I REMOVE THIS SECTION? SEEMS WEAK NOW THAT THE SURROUNDING MATERIAL IS IMPROVED.
\subsubsection{Crowd-sourcing}
% based (large volume of obs, multiple sources. Crowdsourced ref material)
% XXX EXPAND EXPAND, talk about authority and what it means
While \cite{goodchildli2012} found that crowd-sourcing was commonly inadequate for VGI, it can function when the domain is limited and the pool of expertise is vast. In one sense, crowd-sourcing becomes useful here when radio towers of differing quality receive records. Cross-referencing these sources then provides and additionaly layer of consistency, and although this doesn't rely on citizen participation, it does minimize instrument error.

\subsubsection{Social}
% XXX should we just axe this whole section?
Mariners provide regular updates to online services, so attribute data from these sources tends to be high. The ship operators frequently have the best working knowledge of a ships' vitals, much like someone who lives in a specific neighborhood is likely to have a better understanding of local geography. The ship operators can then communicate the data up to various shipping related aggregation sites, who operate the higher levels of the hierarchy, and rely on a group of trusted users for vetting incoming updates.

\subsubsection{Geographic}
% XXX this is BLEH right now, make it not crap.
This brings us to perhaps the most important validation technique: using geography to validate the records. Here, the individual observations are points with time, and I can rely on a few simple tests.  In addition to our point location $\langle x,t \rangle$, have multiple attributes $\langle z \rangle$ provide us a spatio-temporal observation $\langle x,t,z \rangle$. By cross-referencing the attributes, the probability of each attribute-only component can be computed, and from that, infer a likelihood on geometry and time.

I also impose basic validation on the geometries by referencing other geographic facts, as is used in the most pedestrian of GIS functions, the overlay analysis. By checking the data against a land-sea mask, estimations are created as to when the provided location is a physical impossibility. One trick to this is that many ships do travel by river, so these rules must be careful to define what is a traversable area. Additionally, shallow water bodies impose additional constraints on many ships with positive draft. This could be validated (showing, for example, the distance oil tankers keep from land), but has not been implemented here.

For many classes of vessels, ships move between ports. Ships exhibit movement patterns inconsistent with this goal are suspect. However, there are other nodes which require inclusion, such as ballast water exchange points, like one located 100nm offshore of California (Figure \ref{fig:cal-cargo}), and canals, which provide a means of ships to move between otherwise distant locations. However, this remains a powerful validation technique: because the high resolution data is clustered around the shores with strong coverage at the ports, the data contains a disproportionate look at the vessels in transit between this constrained set of locations.

As in many large datasets, the distribution of observations per ship follows an approximate power-law distribution. Using the raw number of observations received in our 15 month window provides another filter. The peak in the kernel density estimation (Figure \ref{fig:obs-per-vessel-log}) is seen around $10^4$ observations, with a clear drop-off after $10^5$ which is consistent with the theoretical maximum (one observation in every sample) of about $6.8 \times 10^5$.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=100mm]{figures/obs-per-vessel-log.pdf}
  \caption{Number of observations per vessel, log scaled.}
  \label{fig:obs-per-vessel-log}
\end{figure}


% highlight importance of geometry + ATTRIBUTES. one alone is insufficient, both can be powerful.

%An aside on 'ships' - ships can have multiple callsigns, MMSI idenfiers, and other data which ideally would locate a specific vessel. We handle this ambiguity methods -- a full version of this can go into supplementals, but worth covering here, because we can map \textbf{type} from observed behavior -- fishing vs. cargo vs. cruise is all obvious when looking at the movement patterns (fold into above 'filtering process' section)

Another important point is that while ship attributes provide us some details as to their nature, categories (such as tanker or cargo) are not based purely on attributes, but also include movement patterns. This is a distinguishing characteristic between the data, as different classes of vessel show distinct movement patterns, which is useful both in validation, and as an output product, since vessel classes have differing effects and interactions. Because this data is stored in a spatial database, I link derived representation back to the records that formed it. While this is a common feature of spatial databases, it is an important trait since data are often provided as simple 'end products' without the provenance to understand its limitations.

% XXX above is good, expand it

%Can link data representations all the way back to attributes of raw data [note: this is true in many spatial databases, right? what makes it special here?]
% - often a requirement but only get 'end products' instead without detailed attributes, or conversely all details on one ship but no way to move between realms fluidly.

\subsection{Data Representations}

% It is necessary to have multiple representations of the data - the data model must flow from the question asked (goodchild, also anything in ebook on GISci?)

After filtering and validating the data as described, I build data representations which bring us closer to answering some of the problems raised in the introduction. Frequently there is no single optimal representation of data, but instead a set of representations which, when matched to particular uses, can be combined to provide insight.

Here, I look at how maintaining both discrete object and continuous fields representations (Figure \ref{fig:representation-in-gis}) allows us to address questions about shipping, including its ecological effects. While the point data alone is too simple for making predictions related to these phenomena, incorporating too much complexity risks making computation infeasible~\citep{de2007geospatial}.

% Some of the effects. link up how specific effects could be monitored by our different representations. Can't just use points to predict phenomena of this nature, but can't incorporate full complexity of reality either; chosen representations are a compromise between those two extremes.

% As in \ref{fig:representation-in-gis}, we can keep track of the ships in a discrete object representation, and after filtering the observations, converting the individual ship locations into movement tracks.

% Merger of data - which can give a single representation of the data

\begin{figure}[htbp]
  \centering
  \includegraphics[width=160mm]{figures/representation-in-gis.pdf}
  \caption{GIS abstractions, this work's specific {\color{DBlue} additions in blue}. Adopted from \cite{Bivand2011}}
  \label{fig:representation-in-gis}
\end{figure}

% It is necessary to have multiple representations of the data - the data model must flow from the question asked (goodchild, also anything in ebook on GISci?)

%Want to link representation to USE, lack of a single simple view which meets all needs. counterpoint to the 'single metric' perspective. 
% [have note: 'link to stats', but now unsure what that means].

% Store the raw observations in a spatial database (PostGIS), use parallelized code to quickly aggregate the results.
\subsection{Ship Types}

% XXX open problem: what designates a 'ship'?
%   Hal: `The biggest flaw is that, long ago, I assumed one ship == one callsign. It turns out, of course, that a single ship can have multiple callsigns (due to sale or reflagging), and that a single callsign can be assigned to multiple ships (e.g. NOAA, and also the Queen Mary/Queen Mary II). So the db really needs its own internal ship UID.`

%  Hal, on 'using MMSI + IMO + Callsign'--  Yeah, that still misses reflagging. I think what I will end up with is a "find-or-create ship with IMO,MMSI,Callsign", together with a manual process for me to force the database to combine two different ship UUID's that actually refer to the same ship. Even that isn't enough, because we see misprogrammed AIS units with dummy MMSI's, and fleetwide MMSI's."

%    ... Almost want a probabilistic model of what ship it is based on the information we do have reliably, and cross-validation with the various online databases... perhaps even validation with Equasis? Could do this for a small subset of the ships, but clearly not them all.

% XXX   - create a ship 'UUID' like feature which incorporates the different aspects: IMO, MMSI, Callsign, Name... we care about specific _ships_ not necessarily what line they're running under or other changes, though this is useful information for certain classes of questions.

%  - collapse all redundant columns from the database once we have this hybrid observation model and can safely assign individual records to a particular ship (instead of a guess based on say, MMSI, which may be misprogrammed).

% XXX mention the ontology work in this space: there are people thinking about this stuff, but it isn't where we need it to be.
% \cite{Vries2009}
% IALA Guideline No. 1028 On The Automatic Identification System (AIS)

An open problem within the maritime community is: what designates a ship? Ships can be classified on a variety of dimensions, including propulsion form, hull material, function and many others. Ontologies have been in development to solve this problem \citep{Vries2009}, but here I focus on use: what is the primary activity the vessel is engaged in? Starting with the initial classes provided by our data sources, I collapsed them into nine major functional groups (Table \ref{table:ships-by-type}). Because the full attributes of each vessel are retained, and frequently include multiple type labels, it is possible to break this down further for future analyses, but these broad classes served well for classifying distinct movement patterns.

Identifiers -- what ship is this -- similarly poses a problem. By incorporating information from many different identifiers and focusing on those less changeable, such as IMO number and radio callsign, we increase the chances of valid matches. But additional attributes such as the Maritime Mobile Service Identity (MMSI), and vessel name are often equally useful, particularly because they are broadcast alongside each AIS record. Vessel operators may fail to maintain this information, so it becomes important to cross validate the attributes to gain reasonable match rates.

% SHIP CLASSES! HOW ARE THEY DEFINED, WHAT ARE THE DIMENSIONS BEING COLLAPSED?
%  a bunch of ways to classify (included in wikipedia article, I also have some notes we defined these by functional groups and their expected ecological differences

% overview of summary statistics of data
\begin{table}[htbp]
  \begin{tabular}{rrrrrr} %{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{9cm}}
    \hline
    Type & Vessels \textit{(AIS)} & Vessels \textit{(VOS)} & fleet size & coverage (\%) & observations (M) \\
    \hline
    Cargo & 25214 & 5838 & 33392\textsuperscript{1} & 75.6 & 665.45 \\
    Tanker & 9758 & 2375 & 14068\textsuperscript{1} & 69.4 & 264.42 \\
    Passenger & 4007 & 777 & 6370\textsuperscript{1} & 62.9 & 142.16 \\
    Support & 9954 & 735 & 25234\textsuperscript{1} & 39.4 & 298.02 \\
    High-speed & 404 & 81 & 1178 & 34.3 & 2.52 \\
    Fishing & 11186 & 349 & 51200\textsuperscript{3} & 21.8 & 6.87 \\
    Pleasure & 20727 & 661 & 800,000\textsuperscript{2} & 2.59 & 267.48 \\
    Other & 9507 & 1400 & -- & -- & 4.75 \\
    Authority & 656 & 55 & -- & -- & 1.44 \\
  \end{tabular}
  \caption{Summary of analyzed ship data\\
  1. \cite{Equasis2011}.\\
  2. \cite{westwood2001global}.\\
  3. \cite{FAOfishing}.}
  \label{table:ships-by-type}
\end{table}
% XXX: high-speed craft from ISL? can't find original ref
% NOTE: the FAO estimates the _full_ fishing fleet size at 4 million vessels, the size clearly has an important effect.
% see: fleet-size.txt for details on this table.


\subsubsection{Raw point data}

% \begin{itemize}
%   \item geoatom with time $\langle x,t,z \rangle$
%   \item formalize what these observations mean
%   \item apply filtering using space-time + attributes
% \end{itemize}

Records are sampled at 600 second intervals (10 minutes). For most ship classes, this sample rate retains the movement patterns, and is a similar sample rate to studies using aggregation to remove noise, like \citep{Vries2009}, which uses piecewise aggregate approximation with w = 30 (300 seconds) to ``strike a good balance between capturing the general movement and ignoring noise''. % XXX NOTE: this is a filtering technique, so it isn't a direct mapping onto the reduced fidelity data we're using.

The spatial databases' historical focus was on accuracy \citep{goodchild1989accuracy}. This showed the value in retaining raw observations, both by minimizing lossy transformations, and providing multiple models of the same data to retain consistency with reality.

\subsubsection{Tracks}

Tracks convert discretely sampled time points into a interpolated continuous phenomena. The uncertainty surrounding the interpolation can be described by a time prism (Figure \ref{fig:time-prism}), which bounds the area based on the maximum velocity of the object at motion. Here, I first constrain the track segments to have movement above 0.5 Kt/hr, below which vessel control is difficult, and an upper bound of 40 Kt/hr, derived empirically from our ship speed distributions (See Figure \ref{fig:vessel-speed-density}). Next I require observations have coordinates bounded by the coordinate space, and exclude any beyond the surface of the earth. I further require that to be considered a track, the above criteria must be met for at least one segment of that vessels transit. The ships are then constrained to move along the shortest distance on a geoid, or great circles, using GeographicLib \citep{karney2012algorithms}. This information is reused in computing the speed along each segment.
% pulled from tracks/shipping_tracks_obs_validated.py

\begin{figure}[h!]
  \centering
    \includegraphics[width=80mm]{images/measurement-theory-for-time-geography-prism.png}
  \caption {A simple space{\textendash}time prism, as in \citep{Miller2005}; original from \citep{Wu2002}}
  \label{fig:time-prism}
\end{figure}

%   \item link to time geography... Hagerstrands conceptual framework... Literature on T-GIS as tracking.
%   \item Goodchild lecture on T-GIS mentioned track interpolation, inferences about activity, track convergence, etc
 % [perhaps drop this for the time being... don't have lit built up on it, unless we can use the anomaly detection stuff]

\subsubsection{Field-based models}

Initially, kernel density estimation was used to produce field based estimates. However, based on the data volume, it proved more useful to provide models directly from discretized tracks, which are used in the two following datasets.

\paragraph{Ship density by type}

The primary output of this work is a field-based density model of ship movement. This view is useful in a wide variety of contexts, from extercises in marine spatial planning (MSP) to detecting conflict zones between resource users, and the simple density estimation in \cite{Halpern2008} remains a highly requested product. % XXX provide better examples
% XXX Why this matters: the view most people want to see; counts of X where and when. Useful for MSP, conflict resolution, detecting conflict zones, etc

Each vessel track was rasterized to both an 90 arcsecond grid (\textasciitilde{}5.5km at the equator) and an equal area grid in the Hobo Dyer projection (Figure \ref{fig:eu-cargo-density}). The latter case insures that the density function is computed on grid cells representing the same area for each cell, unlike the geographic grid where area varies by latitude. A vessel is counted only once for each cell it passes through, as the focus here os on overall movement patterns, and this criteria helps de-emphasize vessels with limited movement. Each raster vessel track was combined using simple map algebra to produce density maps for both the AIS and VOS data, for each of our vessel classes.

For each cell the output density value s calculated as a standardized equal-weighted addition between the two input datasets, AIS and VOS:
\begin{equation}
 s = \frac{R_{AIS}}{max(R_{AIS})} + \frac{R_{VOS}}{max(R_{VOS})} 
\end{equation}

\begin{figure}[h!]
  \centering
    \includegraphics[width=120mm]{figures/cargo-lanes-eu-cropped.png}
  \caption {Cargo density grid, generated by combining AIS and VOS records.}
  \label{fig:eu-cargo-density}
\end{figure}

% Bresenham's line algorithm used for rasterizing the tracks. Only counted a ship moving through a single cell once to get movement patterns v. dockage

\paragraph{Speed density estimations of ships by ship type}

Ship speed plays a critical role in determining the survivability of collisions for many marine species~\citep{Vanderlaan2009}. Speed also directly relates to the emissions profile of a vessel, and it has been shown that speed reduction alone can reduce 50-80\% of greenhouse gas emissions \cite{lack2011impact}. Conversely, decreased speeds require more vessels to ship the same volume of goods or passengers, though companies such as Maersk are mitigating this by moving to significantly larger container ships.

Average speed per cell was calculated as sum speed over all observations $R_{AIS} \cup R_{VOS} = n$, and dividing it by the total number of observations, but only for those locations where a sufficient density $s$ is present: 

\begin{equation}
 \bar{s} = \left\{
   \begin{array}{l l}
    \frac{\sum\limits_{i=0}^n s}{x} & \quad \text{$s \ge 10$}\\
    0 & \quad \text {$s < 10$}
   \end{array}\right.
\end{equation}

% CLARIFY: what are the other effects of speed? anomaly detection?

% calculated the ship average speed over the journey, used that as 'speed value' [pretty bogus, but was quick and I couldn't get the M values in OGR correctly].
% XXX ADD THIS BACK? probably a new paper at that point.
%\subsubsection{Network model of ship travel}

%Some analyses require 'factoring out' geography to the extent possible, such as ecological models (Tilman book), Economic, et cetera. Network theory provides a useful basis of analysing geographically explicit data in a mathematical framework which can incorporate some of the geographic constraints while eliding many details necessary in a spatially-explicit model.

%Best thing here is Kaluza but they totally lost the geography in transit -- can produce a middle ground model which has geographic nodes and edges, but still retains the rigour of the network model. Can get both!

% ...

% Paragraph from one of my position papers --
% One model I’m particularly interested in is hybridized network models using tools like NetworkX, which have the attractive property of allowing mixed field/object representations of the same data simultaneously, hence escaping the common limits of networks as mentioned in ? of every link or edge requiring a discrete value. By imbuing a network model with object-oriented features, some of the challenges I’ve been having representing my ship traffic data vanish. An- other advantage of manipulating graphs as a primitive is their widespread support, including general purpose graph databases which are particularly taking off in the semantic space.

% another pp from a position
% This becomes particular important as the tools of spatial thinking extend across disciplinary boundaries, both in the social and physical sciences (Goodchild and Janelle, 2010; Tilman and Kareiva, 1997). Other domains, such as ecology and economics, are coming to terms with the fact that their historical approaches to keeping simple models (and by extension, limiting model scope to their domain) ignores important spatial context which naturally arises at the unit of analysis (Tilman and Kareiva, 1997; Krugman, 1991).

\subsection{Record Linkage}

By combining authoritative data from a variety of sources (Table \ref{table:ships-data-sources}), we can reconcile our observations, greatly improving the quality of resulting ship movement models. Though we do include two authoritative datasets, the sources are inconsistent, and require an initial step of cross-linking records. This approach was initially developed with medical records, and more recently developed as the record linkage field in computer science~\citep{Christen2012}.

% table describing sources
% SOURCES: ship-id-model.txt
%          ship-id-model/linkages.txt
\begin{table}[htbp]
  \begin{tabular}{rrrrl}%{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{9cm}}
    \hline
    Source & Code & Records & Cross-linked & Attributes \\
    \hline
     Digital Seas & DS & 212166 & 68002 & {\footnotesize name, IMO, MMSI, callsign, type, width, length} \\
      FCC\textsuperscript{1} ULS\textsuperscript{2} & FCC & 319964 & 24531 & {\footnotesize name, MMSI, callsign, class, gross gonnage, length} \\
      ITU\textsuperscript{3} MARS\textsuperscript{4} & ITU & 372183 & 75928 & {\footnotesize name, IMO, MMSI, callsign, class, owner, gross tonnage}\\ 
     VesselTracker & VT & 126534 & 83372 & {\footnotesize name, IMO, MMSI, callsign, class, length}
  \end{tabular}
  \caption{Ship data sources.\\ 
  1. Federal Communications Commission \\ 
  2. Universal Licensing System \\
  3. International Telecommunication Union \\ 
  4. Maritime mobile Access and Retrieval System}
  \label{table:ships-data-sources}
\end{table}

I built a probabilistic model which evaluated all possible pairwise combinations between source records. By using the methodology of record linkage, a set of rules was developed to map records between the six possible source pairs. Each pair was evaluated for common, consistent attributes, and compared against these columns. The software package used, (FRIL, \citealp{Jurczyk2008fril}), provides an Expectation Maximization algorithm to iteratively optimize the column weighting, but due to the large number of records, this proved ineffective. Instead, samples were examined, and the criteria were set by manual tuning both the weightings and acceptance levels to match a training dataset of valid linkages (Table \ref{table:ships-record-linkage-methods}). 

% table describing the record linkage technique used for each data source
% SOURCE: record-linkage/FRIL/config/*.xml
\begin{table}[htbp]
  \begin{tabular}{rrrrrr} %{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{9cm}}
    \hline
    Source $A$ & Source $B$ & acceptance level & column & distance metric & weight \\
    \hline
     DS & ITU & 92 & callsign & Jaro-Winkler\textsuperscript{1} & 50 \\
        &     &    & MMSI & equal & 40 \\
        &     &    & name & Jaro-Winkler & 40 \\
     DS &  VT & 85 & callsign & Jaro-Winkler & 60 \\
        &     &    & IMO & Jaro-Winkler & 20 \\
        &     &    & name & Jaro-Winkler & 20 \\
    FCC & ITU & 85 & callsign & Jaro-Winkler & 95 \\
        &     &    & name & Jaro-Winkler & 5 \\
    FCC &  VT & 95 & callsign & Jaro-Winkler & 66 \\
        &     &    & name & Jaro-Winkler & 5 \\
        &     &    & MMSI & Jaro-Winkler & 24 \\
        &     &    & length & equal & 5 \\
     VT & ITU & 80 & callsign & Jaro-Winkler & 20 \\
        &     &    & MMSI & Edit Distance & 30 \\
        &     &    & name & Jaro-Winkler & 10 \\
        &     &    & IMO & Jaro-Winkler & 40 \\
     DS & FCC & 95 & callsign & equal & 99 \\
        &     &    & name & Jaro-Winkler& 1 \\
  \end{tabular}
  \caption{Ship record linkage methods used. \\
    \textsuperscript{1} Jaro-Winkler distance \citep{winkler1990string}: length $l = 4$ and scaling factor $p = 0.1$}
  \label{table:ships-record-linkage-methods}
\end{table}


For most attributes, either the equal fields (both values are the same) or the Jaro-Winkler distance metric were used. Jaro-Winkler has useful properties for this data: it is effective on both numeric and textual data, and is particularly good in picking up the kinds of errors inherent in user provided data sources such as those used in this study. A study of string comparison metrics found it to be both efficient, and effective, with a high match rate on diverse data~\citep{Cohen2003}. The equations used in the Jaro-Winker distance are described in (Appendix \ref{sec:record-linkage-appendix}).

Once each combination between two sources was finished running in FRIL, a second rule-based method was developed to capture valid pairings initially missed. If vessels had equality in any two attributes of the set ${MMSI, callsign, name}$, if callsign and vessel length matched, or if the IMO number provided was a valid seven digit number, then the pair was marked as linked. This was tested against a number of pairs manually, and successfully caught many of the initially missing yet valid linkages.

\subsubsection{Linkage Validation}

After pairwise linkage, matched records (Table \ref{table:ships-record-linkage-results-summary}) were further cross-linked, % XXX HOW? create-ships-table.py contains the logic.
 to account for vessels appearing in multiple sources. The number of links per ship averaged 3.5 ($\mu = 3.49, \sigma = 0.828$), % XXX STATISTICALLY SIGNIFICANT? the vast majority only have 3-4 links. Tried fitting this data to a variety of distributions, it can be done, but for what end? the 'high' values really indicate errors, and these should be separated out to their relevant subships.
though this distribution is skewed by a handful of vessels which were linked to many vessels incorrectly. To correct these problems and measure the effectiveness of the record linkage steps, I performed validation using the techniques which follow.

Detecting errors in this data is particularly problematic, as the records are highly correlated by nature -- often, IMO number, callsign and name differ by only one character for two ships in the same fleet. We want to keep these kinds of vessels separate, while simultaneously finding small differences due to entry error, which proved difficult. I developed a validation score to remove over-aggressive links between the data, and allow us a second quality check which is tunable to threshold the data, depending on the kinds of error we are willing to accept.

To start with, I evaluated the bad joins present in the data, and the specific traits that were common across the sample. These included:
\begin{enumerate}[noitemsep]
 \item >6 linked records
 \item >1 radio callsign
 \item >1 MMSI
 \item clear name mismatches
 \item vessel assigned to multiple incompatible classes
\end{enumerate}

Based on this, a set of rules was developed to assign a validation score and probable vessel class based on the inputs.  Again Jaro-Winkler was used to compare attribute matches for both ship name and radio callsign, with $1 - d_w$ being added to the validation score. For attributes that had a single value, the attribute score was increased by one, otherwise vessels which had more than two MMSIs or five linked records had one point removed from their validation score. Lastly, if a ship was identified as being in multiple incompatible classes, one point was subtracted for each additional class. Our final scores for all vessels is shown in (Figure \ref{fig:validation-score-hist}).

\begin{figure}[h!]
  \centering
    \includegraphics[width=90mm]{figures/validation-scores-hist.pdf}
  \caption {Validation scores, bin width=0.3}
  \label{fig:validation-score-hist}
\end{figure}

These scores were then used to select valid vessels, and to assign vessels to the nine classes. Only scores exceeding zero were used for the movement models. Finally, though all these steps give us good self-consistency, I wanted to test against even better sources.  % TODO: perform data validation on these observations with Equasis. Sample a handful of records from each class, then perform the validation.
While some of our input datasets are authoritative, the best available data remains commercial. A a 1\% sample of the records were compared to those provided in Equasis \citep{Equasis2011}, which includes validated records from the commercial fleet. This showed that, after cross-linking, the validation score showed good correpsondence with true vessels, though only comparisons to commercial classes of vessels were possible.

% XXX built spatial indexes and reordered the data on disk to match for performance.


\section{\textbf{Results}}
% A concise report of your results. A final report is not a lab log book, so you do not need to include details of every calculation or include every graph.  Most readers get bored if there are too many very similar graphs in a paper. The key requirement is to report all findings that relate directly to your goals and that will be referred to in the discussion.  

% Avoid having the text in the Results section be a simple list of each result or statistical test – integrate, summarize, synthesize, and point out the most important messages you want your readers to take away from the paper.

% What really matters from what we've done?

\subsection{Record Linkage}

Record linkage matched 30-50\% of each record source pair (Table \ref{table:ships-record-linkage-results-summary}), and additional validation boosted this even further. That authoritative data is inconsistent points toward needing better unified and public identifiers than are currently exist.

% XXX move this table to an appendix? doesn't really help tell the story.
% table describing # of records linked betwen each source
% SOURCE: ship-id-model/matches.ods
\begin{table}[htbp]
  \begin{tabular}{rrll} %{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{9cm}}
    \hline
    Source $A$ & Source $B$ & matched records & \% possible matched \\
    \hline
     DS & FCC &  3481 & 50.35\textsuperscript{1} \\
     DS & ITU & 41380 & 30.73 \\
     DS &  VT & 72286 & 53.68 \\
    FCC & ITU & 27874 & 50.58\textsuperscript{1} \\
    FCC &  VT &  5282 & 53.23\textsuperscript{1} \\
     VT & ITU & 54727 & 43.25 \\
  \end{tabular}
  \caption{Ship record linkage results summary. \\
    1. FCC data is US only, \% possible is of US-only data from these sources.}
  \label{table:ships-record-linkage-results-summary}
\end{table}

\subsection{Geographic Validation}

The land-sea mask developed in Section \ref{sec:land-sea-mask}  was compared against each observation: is the point contained within a water body? However, this simple validation technique wasn't sufficient to resolve many observations, which lie at the edge of the two classes when docked and moving near shore (Figure \ref{fig:longbeach-validation}). Due to this and other limitations, the observations 'on land' were retained for the rest of the analysis, but perhaps a better approach would be to apply a local density estimation on the vessels, and determine a mask based on thresholding the data. Instead, most of the on land observations were filtered by using our track generation rules, which by restricting vessel movements to a possible range, generally remove individual erroneous observations, but a more robust technique would be useful for systematic errors.

% XXX: how did we improve data quality by using geographic filtering? what does that tell us, and why does it matter?

\subsection{Ship results}

\subsubsection{Speed}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=100mm]{figures/speed-boxplot.pdf}
  \caption{Boxplot of validated ship speeds.}
  \label{fig:vessel-speed-boxplot}
\end{figure}

Ship speed is an important predictor for a variety of questions, but is challenging to represent spatially, as it is sensitive to the observation frequency in a particular location, along with accurate distance and time measurements. To get a general sense of ship speed, the speed distribution of each vessel class was examined, both through simple boxplots (Figure \ref{fig:vessel-speed-boxplot}), and through a more nuanced kernel density estimation (Figure \ref{fig:vessel-speed-density}). The density estimation shows that for many classes, distinct speed patterns are clearly visible. For example, support vessels, which include tugs and barges move much more slowly than high-speed transport vessels. Other classes are less distinct in speed signature: cargo and tanker vessels have surprisingly similar average speeds, though by breaking this down spatially (Figure \ref{fig:speed-ship-map}), we can see a more nuanced story.

% graphs of SHIP SPEED by type, either using kernel estimation or simple histograms depending on the clarity of the data.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=150mm]{figures/speed-comparison-qqplot.pdf}
  \caption{Distribution of validated ship movement speeds, computed using kernel density comparisons, as described in \citep{bowman1997applied}.}
  \label{fig:vessel-speed-density}
\end{figure}

\begin{figure}[htbp]
  \centerline{\includegraphics[width=160mm]{images/speed_map_labeled.pdf}}
  \caption{Average ship speed examples. Scale shows 10-20 Kts/hr range for all vessels. Of note is the large difference in speeds between the opposite shores of North America.}
  \label{fig:speed-ship-map}
\end{figure}

\subsubsection{Density}

The density maps show the dramatically different movement structure of the major vessel classes: cargo, tankers and passenger ships all exhibit important differences in their movement. 

\begin{figure}[htbp]
  \centerline{\includegraphics[width=220mm]{figures/9fold-map-black-test_cropped_inverted_thesis.png}}
  \caption{Ship movement densities. first row: cargo, tankers, support. second row:  pleasure, passenger, fishing. third row: other, high-speed, authority.}
  \label{fig:9fold-ship-maps}
\end{figure}


\subsubsection{Spatial Autocorrelation}

Geographic features tend to be clustered, exhibiting spatial autocorrelation. Here, we use Moran's I to compute global autocorrelation statistics for our density rasters:
\begin{equation}
I = \frac{n}{\sum_{i=1}^{n}\sum_{j=1}^{n}w_{ij}}
\frac{\sum_{i=1}^{n}\sum_{j=1}^{n}w_{ij}(x_i-\bar{x})(x_j-\bar{x})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}
\end{equation}

where $n$ is the number of cells, and $w_{ij}$ is the spatial weight.

% XXX: suggestion-- ships by season? just static results here, can do some dynamic stuff later.

\section{Discussion}

% what does it mean? interpret the patterns observed within the data... link back to a broader discussion.

Shipping is a major user of the ocean, but little is known about its distribution and effects. Here I attempted to build the first validated and global models of ship movement, to better enable us to manage the ocean effectively. The shipping companies acknowledge the importance of managing the ocean holistically, but lack the scientific knowledge and tools to do so effectively. By incorporating ecological information alongside logistical efficiencies, it should be possible to improve the system robustness.

Marine protected areas (MPAs) have been shown to be effective~\citep{halpern2002marine}, but the multidimensional nature of ocean use is pointing toward dynamic MPAs, which may rely on providing users, such as ship operators, with real-time information about the state of the environment. Marine spatial planning is proving a promising avenue for brining stakeholders together~\citep{merrifield2012marinemap}. This new form of planning has greater data requirements, which in the ocean can be simplified down to three major areas of use: fisheries management, transportation management, and energy management~\citep{Lubchenco2010}. Transportation in the ocean is the least studied of the three, and here we have shown how volunteered geographic information methods, along with volunteered observations, can provide us a way to tackle the data-poor problem.

% - shipping has big economic benefit, but costs are externalized

% - there are good actors in shipping who want to do the right thing, but don't have the tools to do it [cites, +Maersk lady]

% - only scientific community can do this

% - can only do msp by bringing stakeholders together

% - VGI methods provide good way of handling messy data as we try to move it toward 'reality'

% - coupling these approaches with real-time efforts has potential to shift dynamic.

\section{Conclusion}

% State what the data mean, link to question stated in the introduction

% - sumarize results/findings
% - put results into context
% - explain implications
% - link to future work + highlight shortcomings

The future will include global AIS coverage \cite{JonesGoogle2012,carson2012satellite}, but methods to validate and integrate this data into a scientifically useful system don't yet exist. Here we've shown that by using VGI methods, we can incorporate many data dimensions and correct for multiple forms of error present in the data.

The approach outlined here is in many ways just the beginning: logical next steps would be deriving true cost-path movement models for the ships, determining the predominant direction within each cell, and producing an abstract network model from the data.

% The ship classifications should be derived riguously, perhaps directly relying on observation data such as those presented here~\citep{adams2011constructing}.

% XXX XXX LIMITATIONS -- START HERE.

% phantom ships phenomena

% time saving meausure: reverse engineer it: START WITH WHAT WE Don't KNOW and what ISN'T RESOLVED
% - work it backward to what we DO HAVE.
%  - START WITH THE CONSTRAINTS FIRST...
%   - HOW WILL WE COORDINATE TO MAKE THIS HAPPEN, WHO SHOULD DO IT?
\bibliography{refs/thesis,refs/links,refs/vgi,refs/prospectus,refs/standards,refs/software}
%\bibliographystyle{plainnat}
\bibliographystyle{jss}
\end{document}
